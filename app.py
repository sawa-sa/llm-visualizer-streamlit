import numpy as np
import streamlit as st
from config import DEFAULT_PROMPTS, DEFAULT_TEMPERATURE, DEFAULT_TOP_P, DEFAULT_TOP_K
from model_loader import load_model
from generator import generate_step
from visualizer import plot_topk, plot_attention

if "input_ids" not in st.session_state:
    st.session_state.input_ids = None
if "generated_tokens" not in st.session_state:
    st.session_state.generated_tokens = []
if "steps" not in st.session_state:
    st.session_state.steps = []
if "step_index" not in st.session_state:
    st.session_state.step_index = 0
if "prompt" not in st.session_state:
    st.session_state.prompt = DEFAULT_PROMPTS[0]
if "prompt_initialized" not in st.session_state:
    st.session_state.prompt_initialized = False
if "head_select" not in st.session_state:
    st.session_state.head_select = "Average"

model, tokenizer = load_model()

explore_mode = st.checkbox(
    "ğŸ”€ æ¢ç´¢ãƒ¢ãƒ¼ãƒ‰: é€”ä¸­ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´ã‚’è¨±å¯",
    value=False,
    help="ã‚ªãƒ•ã«ã™ã‚‹ã¨ç”Ÿæˆé–‹å§‹å¾Œã«å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ãƒƒã‚¯ã—ã¾ã™"
)
generation_started = (len(st.session_state.steps) > 0) and not explore_mode

st.title("ğŸ” GPT-2 Medium å¯è¦–åŒ–ãƒ‡ãƒ¢")

example_prompt = st.selectbox(
    "ğŸ§ª è©¦ã—ã¦ã¿ãŸã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸ã‚“ã§ãã ã•ã„ï¼ˆç·¨é›†ã‚‚å¯èƒ½ï¼‰",
    ["ï¼ˆâ†é¸ã‚“ã§ãã ã•ã„ï¼‰"] + DEFAULT_PROMPTS,
    key="prompt_selector",
    disabled=generation_started
)
if example_prompt != "ï¼ˆâ†é¸ã‚“ã§ãã ã•ã„ï¼‰" and not st.session_state.prompt_initialized:
    st.session_state.prompt = example_prompt
    st.session_state.prompt_initialized = True

prompt = st.text_input(
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
    value=st.session_state.prompt,
    disabled=generation_started
)
ss = st.session_state

temperature = st.slider(
    "Temperature",
    min_value=0.0,
    max_value=2.0,
    value=DEFAULT_TEMPERATURE,
    step=0.1,
    disabled=generation_started
)
ntop_p = st.slider(
    "Top-p (Nucleus sampling)",
    min_value=0.0,
    max_value=1.0,
    value=DEFAULT_TOP_P,
    step=0.01,
    help="Top-p < 1.0 ã®ã¨ãã¯ Top-p ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€Top-p = 1.0 ã®æ™‚ã¯ Top-K ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°",
    disabled=generation_started or temperature < 1e-5
)
ntop_k = st.slider(
    "Top-K sampling",
    min_value=1,
    max_value=50,
    value=DEFAULT_TOP_K,
    step=1,
    help="Top-p = 1.0 ã®ã¨ãã®ã¿æœ‰åŠ¹",
    disabled=generation_started or ntop_p < 1.0 or temperature < 1e-5
)

st.markdown("---")
if generation_started:
    st.markdown("ğŸ”’ ç”Ÿæˆé–‹å§‹å¾Œã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´ä¸å¯ã§ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆæœŸåŒ–ã§ãƒªã‚»ãƒƒãƒˆã€‚")
elif temperature < 1e-5:
    st.markdown("âš ï¸ Temperature=0 ã®ãŸã‚ Top-p ã¨ Top-K ã¯ç„¡åŠ¹ã§ã™")
elif ntop_p < 1.0:
    st.markdown("âš ï¸ Top-K ã¯ç¾åœ¨ç„¡åŠ¹ã§ã™ï¼ˆTop-p æœ‰åŠ¹ï¼‰")
else:
    st.markdown("âš ï¸ Top-p ã¯ç¾åœ¨ç„¡åŠ¹ã§ã™ï¼ˆTop-K æœ‰åŠ¹ï¼‰")

if st.button("ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆæœŸåŒ–"):
    ss.input_ids = tokenizer.encode(ss.prompt, return_tensors="pt")
    ss.generated_tokens = []
    ss.steps = []
    ss.step_index = 0
    ss.prompt_initialized = False
    ss.head_select = "Average"

if ss.input_ids is None:
    st.warning("ã¾ãšã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

chart_placeholder = st.empty()
attention_placeholder = st.empty()

if st.button("â–¶ï¸ ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ"):
    result = generate_step(
        ss.input_ids,
        model,
        tokenizer,
        temperature,
        ntop_p,
        ntop_k,
    )
    ss.input_ids = result["input_ids"]
    ss.steps.append(result["step_data"])
    ss.step_index = len(ss.steps) - 1

if ss.steps:
    idx = ss.step_index
    step = ss.steps[idx]

    c1, _, c3 = st.columns([1, 2, 1])
    c1.button("â† å‰ã¸", on_click=lambda: ss.update(step_index=max(ss.step_index - 1, 0)), key="prev_button", disabled=(idx == 0))
    c3.button("æ¬¡ã¸ â†’", on_click=lambda: ss.update(step_index=min(ss.step_index + 1, len(ss.steps) - 1)), key="next_button", disabled=(idx == len(ss.steps) - 1))

    st.markdown(f"**Step {idx+1}/{len(ss.steps)}**")

    if temperature < 1e-5:
        topk_title = "Top-1 (Greedy decoding)"
        topk_limit = 1
    elif ntop_p < 1.0:
        topk_title = f"Top-p Distribution (p={ntop_p:.2f})"
        topk_limit = 10
    else:
        topk_title = f"Top-K Distribution (k={ntop_k})"
        topk_limit = ntop_k

    fig = plot_topk(
        tokens=step["tokens"],
        values=step["values"],
        ids=step["ids"],
        chosen=step["chosen"],
        top_k=topk_limit,
        temperature=temperature,
        title=topk_title
    )
    chart_placeholder.pyplot(fig)

    attn = step["attn"]
    if attn.ndim == 2:
        attn = attn[np.newaxis, ...]
    num_heads = attn.shape[0]
    options = ["Average"] + [f"Head {i}" for i in range(num_heads)]
    sel = st.selectbox("Attention Head ã‚’é¸æŠ", options, key="head_select", index=options.index(ss.head_select))

    if sel != ss.head_select:
        ss.head_select = sel

    if sel == "Average":
        attn_to_plot = attn.mean(axis=0)
        title = "Average"
    else:
        head_idx = int(sel.split()[1])
        attn_to_plot = attn[head_idx]
        title = sel

    attn_fig = plot_attention(attn_to_plot, step["all_toks"], title=title)
    attention_placeholder.pyplot(attn_fig, clear_figure=False)

st.markdown("### ğŸ§  æœ€çµ‚çš„ãªå‡ºåŠ›æ–‡")
st.write(tokenizer.decode(ss.input_ids[0], skip_special_tokens=True))
